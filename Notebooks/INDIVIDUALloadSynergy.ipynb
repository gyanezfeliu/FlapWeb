{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "#from LoadData.models import Experiment, Sample, Dna, Vector, Measurement, Inducer, LoadProcess\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import json\n",
    "import os\n",
    "import openpyxl as opxl\n",
    "from itertools import islice\n",
    "import csv\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef fix_synergy_time(df):\\n    t = np.array([])\\n    for i, value in enumerate(df['Time']):\\n        if i > 0:\\n            if df['Time'].iloc[i].hour < df['Time'].iloc[i-1].hour:\\n                t = np.append(t, [24 + value.hour + value.minute/60 + value.second/3600])\\n            else:\\n                t = np.append(t, [value.hour + value.minute/60 + value.second/3600])\\n        else:\\n            t = np.append(t, [value.hour + value.minute/60 + value.second/3600])\\n    df['Time'] = t\\n\""
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CON DATAFRAME\n",
    "\"\"\"\n",
    "def fix_synergy_time(df):\n",
    "    t = np.array([])\n",
    "    for i, value in enumerate(df['Time']):\n",
    "        if i > 0:\n",
    "            if df['Time'].iloc[i].hour < df['Time'].iloc[i-1].hour:\n",
    "                t = np.append(t, [24 + value.hour + value.minute/60 + value.second/3600])\n",
    "            else:\n",
    "                t = np.append(t, [value.hour + value.minute/60 + value.second/3600])\n",
    "        else:\n",
    "            t = np.append(t, [value.hour + value.minute/60 + value.second/3600])\n",
    "    df['Time'] = t\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CON NUMPY\n",
    "def fix_synergy_time(t_old):\n",
    "    t_new = np.array([])\n",
    "    for i, value in enumerate(t_old):\n",
    "        if i > 0:\n",
    "            if t_old[i].hour < t_old[i - 1].hour:\n",
    "                t_new = np.append(t_new, [24 + value.hour + value.minute/60 + value.second/3600])\n",
    "            else:\n",
    "                t_new = np.append(t_new, [value.hour + value.minute/60 + value.second/3600])\n",
    "        else:\n",
    "            t_new = np.append(t_new, [value.hour + value.minute/60 + value.second/3600])\n",
    "    return t_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(col, measures):\n",
    "    return [(celda.value, celda.row, opxl.utils.column_index_from_string(celda.column))\n",
    "        for celda in col\n",
    "        if celda.value in measures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo Metadata desde el archivo JSON\n",
    "data_str = open('MetaTest.json').read()\n",
    "data = json.loads(data_str)\n",
    "df_json = pd.read_json(data)\n",
    "columns = [x+str(y) for x in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'] for y in range(1,13)]\n",
    "df_json.columns = columns\n",
    "df_json.index = ['Strain', 'Media', 'DNA']\n",
    "\n",
    "#If el usuario no me da el nombre del experimento, le pongo el nombre del archivo de datos\n",
    "experiment_name = os.path.basename('ExpTest.xlsx').split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estas medidas deben venir dadas por el usuario y yo debo sumar \"Results\"\n",
    "medidas = ['OD600:600', 'RFP-YFP:585/10,620/15', 'RFP-YFP:500/27,540/25', 'CFP:420/50,485/20', 'Results']\n",
    "\n",
    "wb = opxl.load_workbook(filename = 'ExpTest.xlsx', data_only=True)\n",
    "ws = wb['Data']\n",
    "machine_name = ws['B'][8].value + str(ws['B'][9].value)\n",
    "\n",
    "# Completar esta lista para todos los posibles valores de longitudes de onda\n",
    "name_map = {'OD600:600':'OD', 'RFP-YFP:500/27,540/25':'YFP', 'CFP:420/50,485/20':'CFP',\n",
    "'RFP-YFP:585/10,620/15':'RFP'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_rows = find_index(ws['A'], medidas)\n",
    "ws.delete_rows(0, lista_rows[0][1] - 1)\n",
    "lista_rows2 = find_index(ws['A'], medidas)\n",
    "\n",
    "# No borro results porque me sirve como punto de stop\n",
    "#ws.delete_rows(lista_rows2[len(lista_rows2)-1][1]-1, 200)\n",
    "#lista_rows3 = find_index(ws['A'], medidas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraída como array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí empiezo el ciclo de armar el array con las series de tiempo\n",
    "\n",
    "# array consolidado que tiene los nombres para cada measurement\n",
    "#names = np.array([]).astype('object')\n",
    "names = np.array([], dtype='str')\n",
    "# array consolidado que tiene los measurement\n",
    "data = np.array([])\n",
    "# array consolidado que tiene los tiempos de los measurements\n",
    "times = np.array([])\n",
    "\n",
    "# datos que fueron extraído del excel del lector de placas\n",
    "raw_data = np.array(list(ws.values))\n",
    "#raw_data = np.delete(raw_data, 2, 1)\n",
    "\n",
    "# cantidad de los datos que se tomaron\n",
    "dim = lista_rows2[1][1] - lista_rows2[0][1] - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso los datos a un array\n",
    "for i in range(len(lista_rows2)-1):\n",
    "    # names for the measurements\n",
    "    name = np.zeros(dim)\n",
    "    name = name.astype('str')\n",
    "    name[:] = name_map[lista_rows2[i][0]]\n",
    "    names = np.concatenate((names, name), axis=0)\n",
    "    \n",
    "    # AHORA ASUME QUE ES PARA TODOS LOS POCILLOS (A1 hasta H12), LUEGO DEBE CONSIDERAR SOLO LOS INDICADOS \n",
    "    # POR EL USUARIO\n",
    "    # measurements\n",
    "    data_array = raw_data[lista_rows2[0][1]+2:lista_rows2[1][1]-2, 3:].astype('float64')\n",
    "    if i == 0:\n",
    "        data = data_array\n",
    "    else:\n",
    "        data = np.concatenate((data, data_array), axis=0)\n",
    "    \n",
    "    # times for the measurements\n",
    "    time = raw_data[lista_rows2[0][1]+2:lista_rows2[1][1]-2, 1]\n",
    "    time = fix_synergy_time(time)\n",
    "    times = np.concatenate((times, time), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# índice para recorrer las columnas del array de los datos\n",
    "max_cols = len(df_json.columns)\n",
    "#max_cols= 0\n",
    "col_ind = 0\n",
    "max_dind = len(data[:, 0])\n",
    "#max_dind = 96\n",
    "dind = 0\n",
    "cont=0\n",
    "\n",
    "# HACER UN IF DE VERIFICACION DE QUE LAS DIMENSIONES CALZAN\n",
    "    # max_cols con el numero de cols de data\n",
    "    # len(data[:, 0]) == dim * len(np.unique(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar los datos en la BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Experiment\n",
    "#e = Experiment(name=experiment_name, machine=machine_name)\n",
    "#e.save()\n",
    "\n",
    "# 2) Sample\n",
    "# get experiment_id\n",
    "# row, col, media, strain\n",
    "\n",
    "# 3) DNA\n",
    "# name\n",
    "\n",
    "# Empiezo a recorrer los platillos que están en df_json: indexes: strain, media, dna:\n",
    "\n",
    "#col_name corresponde a A1, A2, ..., H12\n",
    "#col_serie corresponde a la metadata para esa celda, por ej:\n",
    "'''\n",
    "Strain          {'name': 'data', 'value': 'None'}\n",
    "Media     {'name': 'data', 'value': 'M9-glucosa'}\n",
    "DNA             {'name': 'data', 'value': 'None'}\n",
    "'''\n",
    "for col_name, col_serie in df_json.iteritems():\n",
    "    dind = 0\n",
    "    #existing_dna = [i.name for i in Dna.objects.all()]\n",
    "    plate_row = col_name[0]\n",
    "    plate_col = col_name[1:]\n",
    "    st = col_serie['Strain']['value']\n",
    "    med = col_serie['Media']['value']\n",
    "    #s = Sample(experiment=e, row=plate_row, col=plate_col, media=med, strain=st)\n",
    "    #s.save()\n",
    "    DNA_name = col_serie['DNA']['value']\n",
    "\n",
    "    if DNA_name != 'None':\n",
    "        existing_dna = []\n",
    "        if DNA_name not in existing_dna:\n",
    "            #d = Dna(name=DNA_name, sboluri='')\n",
    "            #d.save()\n",
    "            pass\n",
    "        else:\n",
    "            #d = Dna.objects.filter(name__exact=DNA_name)[0]\n",
    "            #v = Vector(dna=d, sample=s)\n",
    "            #v.save()\n",
    "            pass\n",
    "\n",
    "    #while(col_ind < max_cols):\n",
    "    while(dind < max_dind):\n",
    "    #One measure, of a given measurement name(OD, CFP, etc), at a given time from a given well (A1,.., H12)\n",
    "        t = times[dind]\n",
    "        n = names[dind]\n",
    "        v = data[:, col_ind][dind]\n",
    "        #m = Measurement(sample=s, name=n, value=v, time=t)\n",
    "        #m.save()\n",
    "        dind += 1\n",
    "    col_ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37248\n"
     ]
    }
   ],
   "source": [
    "print(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37248"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "96*97*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plate_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12'"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plate_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
