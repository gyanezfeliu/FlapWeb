{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import os\n",
    "import openpyxl as opxl\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_file(route, file_format):\n",
    "    files = os.listdir(route)\n",
    "    # Sends each file to be loaded\n",
    "    for file in files:\n",
    "        if '.xlsx' in file:\n",
    "            load(file, file_format)\n",
    "        else:\n",
    "            # Get an error message\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file_name, file_format, experiment_name=None, machine_name=None):\n",
    "    # Needs to get all experiments:\n",
    "    existing_exps = []\n",
    "    if not experiment_name:\n",
    "        experiment_name = os.path.basename(file_name)\n",
    "    \n",
    "    # If experiment already exists\n",
    "    if experiment_name in existing_exps:\n",
    "            print('Experiment ', experiment_name, ' already exists in database. Have you already uploaded this file, or one with the same name? Skipping file.')\n",
    "    else:\n",
    "        wb = opxl.load_workbook(filename = file_name, data_only=True)\n",
    "        ws = wb['Data']\n",
    "        print('Uploading data from file '+file_name)\n",
    "        \n",
    "        if 'synergy' in file_format:\n",
    "            if not machine_name:\n",
    "                machine_name = st['B'][8].value + str(st['B'][9].value)\n",
    "            exp = load_meta_info(wb, experiment_name, machine_name, session, engine)\n",
    "            #exp = load_synergy_data(st, exp, session, medidas)\n",
    "            pass\n",
    "        elif 'bmg' in file_format:\n",
    "            if not machine_name:\n",
    "                machine_name = 'bmg'\n",
    "            exp = load_meta_info(wb, experiment_name, machine_name, session, engine)\n",
    "            exp = load_bmg_data(st, exp, session, engine)\n",
    "            pass\n",
    "        else:\n",
    "            print('File format %s not supported'%file_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meta_info(wb, experiment_name, machine_name):\n",
    "    # e = Experiment(name=experiment_name, machine=machine_name)\n",
    "    # e.save()\n",
    "    \n",
    "    # Dictionary where dataframes will be stored and send\n",
    "    meta_dict = {'Strain_name':'', 'Strain_df':'', \n",
    "                 'Media_name':'', 'Media_df':'', \n",
    "                 'DNA_name':'', 'DNA_df':'', \n",
    "                 'Inducer_name':'', 'Inducer_df':''}\n",
    "\n",
    "    meta_dict['Strain_name'], meta_dict['Strain_df'] = table_values(wb['Strains'], 1)\n",
    "    meta_dict['Media_name'], meta_dict['Media_df'] = table_values(wb['Media'], 1)\n",
    "    meta_dict['DNA_name'], meta_dict['DNA_df'] =  get_all_tables(wb['DNA'])\n",
    "    \n",
    "    if 'Inducers' in wb.sheetnames:\n",
    "        meta_dict['Inducer_name'], meta_dict['Inducer_df'] = get_all_tables(wb['Inducers'])\n",
    "    else:\n",
    "        meta_dict['Inducer_name'], meta_dict['Inducer_df'] = [], []\n",
    "    \n",
    "    # It also should return the experiment created\n",
    "    return meta_dict#, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_data(e, dict_meta, df_cons, columns):\n",
    "    # El método load_meta_info retorna el experimento e\n",
    "    for index, value in enumerate(columns):\n",
    "        row = value[0]\n",
    "        col = int(value[1:])\n",
    "\n",
    "        # Metadata value for each well\n",
    "        s_strain = dict_meta['Strain_df'].at[row, col]\n",
    "        s_media = dict_meta['Media_df'].at[row, col]\n",
    "        # s = Sample(experiment_id=e, row=row, col=col, media=s_media, strain=s_strain)\n",
    "        # s.save()\n",
    "\n",
    "        for df_dna in dict_meta['DNA_df']:\n",
    "            s_dna = df_dna.at[row, col]\n",
    "            if dna != 'None': ### Y no existe ya en la tabla ID\n",
    "                # d = Dna(name=s_dna, sboluri='')\n",
    "                # d.save()\n",
    "                # v = Vector(dna_int=d, sample_id=s)\n",
    "                # v.save()\n",
    "                pass\n",
    "            else:\n",
    "                ### Buscar el id del Dna con ese nombre y pasárselo para que lo asigne a la tabla vector\n",
    "                # v = Vector(dna_int=d, sample_id=s)\n",
    "                # v.save()\n",
    "                pass\n",
    "\n",
    "        if len(dict_meta['Inducer_df']) > 0:\n",
    "            for i, df_ind in enumerate(dict_meta['Inducer_df']):\n",
    "                conc = df_ind.at[row, col]\n",
    "                ind_name = dict_meta['Inducer_name'][i]\n",
    "                # i = Inducer(sample_id=s, concentration=conc, pubchemid=ind_name)\n",
    "                # i.save()\n",
    "\n",
    "        # Data value for earch well\n",
    "        for i, val in df_cons[row+str(col)]:\n",
    "            m_name = df_cons['name'].iloc[i]\n",
    "            m_value = val\n",
    "            m_time = df_cons['Time'].iloc[i]\n",
    "            # m = Measurement(sample_id=s, name=m_name, value=m_value, time=m_time)\n",
    "            # m.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_in_sublists(lst, value):\n",
    "    for sub_i, sublist in enumerate(lst):\n",
    "        try:\n",
    "            return (sub_i, sublist.index(value))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    raise ValueError('%s is not in lists' % value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tables(ws):\n",
    "    # Return a list of tables (8x12) as lists in worksheet\n",
    "    # Tables are assumed to be ordered vertically\n",
    "    length = len(ws['A'])\n",
    "    ntables = (length + 1) // 10\n",
    "    table_list = []\n",
    "    names_list = []\n",
    "    for i in range(ntables):\n",
    "        name,values = table_values(ws, i*10+1)\n",
    "        table_list.append(values)\n",
    "        names_list.append(name)\n",
    "    return names_list,table_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It returns a 96 items list, from west to east, north to south from the plate. \n",
    "# Now it returns a df\n",
    "def table_values(ws, row):\n",
    "    name = ws[row][0].value\n",
    "    vals = []\n",
    "    for cell_row in range(row + 1, row + 9):\n",
    "        for cell_col in range (1, 13):\n",
    "            val = ws[cell_row][cell_col].value\n",
    "            if not val:\n",
    "                vals.append(0)\n",
    "            else:\n",
    "                vals.append(val)\n",
    "    df_vals = pd.DataFrame(np.reshape(np.array(vals), (8,12)), \n",
    "                               index=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'], \n",
    "                               columns=range(1,13))\n",
    "    return name, df_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bmg_data(times, rows_data, names, columns):\n",
    "    l = int(len(rows_data[0])/3)\n",
    "    \n",
    "    t_CFP = times[:l]\n",
    "    CFP = [r[:l] for r in rows_data]\n",
    "    t_YFP = times[l:160]\n",
    "    YFP = [r[l:160] for r in rows_data]\n",
    "    t_OD = times[160:]\n",
    "    OD = [r[160:] for r in rows_data]\n",
    "\n",
    "    list_data = [CFP, YFP, OD]\n",
    "    list_time = [t_CFP, t_YFP, t_OD]\n",
    "    \n",
    "    # List with time series for 3 measurements\n",
    "    cols = columns[:]\n",
    "    cols.insert(0, 'Time')\n",
    "    cols.append('name')\n",
    "\n",
    "    df_cons = pd.DataFrame(columns= cols) \n",
    "    for i, value in enumerate(list_data):\n",
    "        df = pd.DataFrame(value)\n",
    "        df = df.transpose()\n",
    "        df.columns = columns\n",
    "        df.insert(0, 'Time', list_time[i])\n",
    "        df['name'] = names[i]\n",
    "        df_cons = df_cons.append(df, ignore_index=True)\n",
    "    return df_cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bmg_data(ws, columns): # Give experiment as an argument !!\n",
    "    rawdata = [[cell.value for cell in row] for row in ws.iter_rows()]\n",
    "\n",
    "    # Work out location of header row, and column/row numbers\n",
    "    try:\n",
    "        (headerrow,ccol) = find_in_sublists(rawdata,'Well Col')\n",
    "        (headerrow,crow) = find_in_sublists(rawdata,'Well Row')\n",
    "    except ValueError:\n",
    "        (headerrow,ccol) = find_in_sublists(rawdata,'Well\\nCol')\n",
    "        (headerrow,crow) = find_in_sublists(rawdata,'Well\\nRow')\n",
    "\n",
    "    # Time is on row below headers\n",
    "    timerow = headerrow+1\n",
    "    # Data is on rows below time\n",
    "    datarow = timerow+1\n",
    "    headers = rawdata[headerrow]\n",
    "\n",
    "    # Find where the data is in each row by looking for 1st 'Raw Data'\n",
    "    cdata = next((i for i,v in enumerate(headers) if 'Raw Data' in v))\n",
    "\n",
    "    # Pull out row,col and data for each row\n",
    "    # Try combinations of alpha/numeric for row/col\n",
    "    try:\n",
    "        rows = [(ord(row[crow].upper())-64, int(row[ccol]), [float(v) for v in row[cdata:]]) for row in rawdata[datarow:]]\n",
    "    except ValueError:\n",
    "        rows = [(int(row[ccol]), ord(row[crow].upper())-64, [float(v) for v in row[cdata:]]) for row in rawdata[datarow:]]\n",
    "\n",
    "    # Pull out time of each data point\n",
    "    times = rawdata[timerow][cdata:]\n",
    "    # Put just data apart\n",
    "    rows_data = [r[2] for r in rows]\n",
    "    names = ['CFP', 'YFP', 'OD']\n",
    "\n",
    "    df_cons = clean_bmg_data(times, rows_data, names, columns)\n",
    "    \n",
    "    return df_cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans the main df\n",
    "def clean_synergy_data(names, df, lista_rows):\n",
    "    df_cons = pd.DataFrame(columns=df.columns)\n",
    "    for i, value in enumerate(lista_rows):\n",
    "        if i == 0:\n",
    "            df2 = pd.DataFrame(df.iloc[0:lista_rows[i][1] - 3])\n",
    "        else:\n",
    "            df2 = pd.DataFrame(df.iloc[lista_rows[i-1][1] + 1:lista_rows[i][1] - 3])\n",
    "        df2['name'] = names[i]\n",
    "        fix_synergy_time(df2)\n",
    "        df_cons = df_cons.append(df2, ignore_index=True, sort=False)\n",
    "    return df_cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes time's format from datetime to fraction\n",
    "def fix_synergy_time(df):\n",
    "    t = np.array([])\n",
    "    for i, value in enumerate(df['Time']):\n",
    "        if i > 0:\n",
    "            if df['Time'].iloc[i].hour < df['Time'].iloc[i-1].hour:\n",
    "                t = np.append(t, [24 + value.hour + value.minute/60 + value.second/3600])\n",
    "            else:\n",
    "                t = np.append(t, [value.hour + value.minute/60 + value.second/3600])\n",
    "        else:\n",
    "            t = np.append(t, [value.hour + value.minute/60 + value.second/3600])\n",
    "    df['Time'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lista_rows(ws, medidas):\n",
    "    lista_rows = [(celda.value, celda.row, opxl.utils.column_index_from_string(celda.column)) \n",
    "                  for celda in ws['A'] \n",
    "                  if celda.value in medidas]\n",
    "    return lista_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_synergy_data(medidas, ws):\n",
    "    rows_ini = lista_rows(ws, medidas)\n",
    "    ws.delete_rows(0, rows_ini[0][1] + 1)\n",
    "    rows = lista_rows(ws, medidas)\n",
    "\n",
    "    data = ws.values\n",
    "    cols = next(data)[1:]\n",
    "    data = list(data)\n",
    "    idx = [r[0] for r in data]\n",
    "    data = (islice(r, 1, None) for r in data)\n",
    "    df = pd.DataFrame(data, columns=cols)\n",
    "    df = df.drop('T° OD600:600', axis=1)\n",
    "    \n",
    "    name_map = {'OD600:600':'OD', 'RFP-YFP:500/27,540/25':'YFP', 'CFP:420/50,485/20':'CFP', 'RFP-YFP:585/10,620/15':'RFP'}\n",
    "    names = [name_map[rows_ini[i][0]] for i in range(len(rows_ini)-1)]\n",
    "    \n",
    "    df_cons = clean_synergy_data(names, df, rows)\n",
    "    return df_cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Archivos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [x+str(y) for x in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'] for y in range(1,13)]\n",
    "medidas = ['OD600:600', 'RFP-YFP:585/10,620/15', 'RFP-YFP:500/27,540/25', 'CFP:420/50,485/20', 'Results']\n",
    "\n",
    "# BMG\n",
    "files = os.listdir('datafiles/bmg/to_upload/')\n",
    "for file_name in files:\n",
    "    wb = opxl.load_workbook(filename = file_name, data_only=True)\n",
    "    ws = wb['Data']\n",
    "    \n",
    "    experiment_name = os.path.basename(file_name).split('/')[-1].split('.')[0]\n",
    "    machine_name = 'bmg'\n",
    "    \n",
    "    #dict_meta, e = load_meta_info(wb, experiment_name, machine_name)\n",
    "    dict_meta = load_meta_info(wb, experiment_name, machine_name)\n",
    "    df_cons = load_bmg_data(ws, columns)\n",
    "    #upload_data(e, dict_meta, df_cons, columns)\n",
    "    upload_data(dict_meta, df_cons, columns)\n",
    "    \n",
    "# Synergy\n",
    "files = os.listdir('datafiles/synergy/to_upload/')\n",
    "for file_name in files:\n",
    "    wb = opxl.load_workbook(filename = file_name, data_only=True)\n",
    "    ws = wb['Data']\n",
    "    \n",
    "    experiment_name = os.path.basename(file_name).split('/')[-1].split('.')[0]\n",
    "    machine_name = ws['B'][8].value + str(ws['B'][9].value)\n",
    "    \n",
    "    dict_meta = load_meta_info(wb, experiment_name, machine_name)\n",
    "    df_cons = load_synergy_data(medidas, ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testeo de carga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillermo/anaconda3/lib/python3.6/site-packages/openpyxl/reader/worksheet.py:318: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Tirar este desde un main para que lo haga con todos los archivos de la carpeta\n",
    "\n",
    "columns = [x+str(y) for x in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'] for y in range(1,13)]\n",
    "\n",
    "files = os.listdir('datafiles/bmg/to_upload/')\n",
    "file_name = 'datafiles/bmg/to_upload/Tim260913.xlsx'\n",
    "experiment_name = os.path.basename(file_name).split('/')[-1].split('.')[0]\n",
    "machine_name = 'M1'\n",
    "wb = opxl.load_workbook(filename = file_name, data_only=True)\n",
    "ws = wb['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_meta = load_meta_info(wb, experiment_name, machine_name)\n",
    "df_cons = load_bmg_data(ws, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta info debe ser recibida al inicio de la carga de datos\n",
    "file_name = 'datafiles/synergy/to_upload/Cinetica 1 rep 3 base de datos.xlsx'\n",
    "experiment_name = os.path.basename(file_name).split('/')[-1].split('.')[0]\n",
    "\n",
    "wb = opxl.load_workbook(filename = file_name, data_only=True)\n",
    "ws = wb['Data']\n",
    "machine_name = ws['B'][8].value + str(ws['B'][9].value)\n",
    "\n",
    "#Debería venir desde el front\n",
    "medidas = ['OD600:600', 'RFP-YFP:585/10,620/15', 'RFP-YFP:500/27,540/25', 'CFP:420/50,485/20', 'Results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_meta = load_meta_info(wb, experiment_name, machine_name)\n",
    "df_cons = load_synergy_data(medidas, ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
